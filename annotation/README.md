# Annotation

## I Direct Evidence Predictions:

### RNAseq mapping

Reads were mapped using the STAR with the script [`a_rnaseq-mapping.sh`](a_rnaseq-mapping.sh) after merging all the forward reads and the reverse reads as to single file each.

### Assembly

The bam files generated by the mapping was used as input for generating genome-guided transcript assembly using the script [`b_transcript-assembly.sh`](b_transcript-assembly.sh). This generates `gtf` file for each assembly progarm

### Mikado

1. The initial setup for Mikado was done using the script [`c_prepare-direct-evidence.sh`](c_prepare-direct-evidence.sh). This will also need:
    - [`fasta-splitter.pl`](https://github.com/ISUgenomics/common_scripts/blob/master/fasta-splitter.pl)
    - [`runBLASTx.sh`](runBLASTx.sh)
    - [`makeSLURMp.py`](https://github.com/ISUgenomics/common_scripts/blob/master/makeSLURMp.py)
    - [`runTransDecoder.sh`](runTransDecoder.sh)
    - [`makeSLURMs.py`](https://github.com/ISUgenomics/common_scripts/blob/master/makeSLURMs.py)
2. The Mikado pick was run using [`d_finalize-direct-evidence.sh`](d_finalize-direct-evidence.sh). The settings files for this run are:
    - [`plants.yaml`](assets/plants.yaml)
    - [`config.toml`](assets/config.toml)
3. Post processing clean the output file to retain only the features listed as coding in the `gff3` file using [`mikado-process-gff3.sh`](mikado-process-gff3.sh).

## II _ab initio_ Predictions

Using BRAKER with aligned RNAseq reads (bam file) and direct-evidence proteins, ab initio predictions were run using the script [`e_runBraker-prot-and-rnaseq.sh`](e_runBraker-prot-and-rnaseq.sh)


## III Filtering _ab initio_

### 1. TE containing genes

To filter TE containing genes from BRAKER, TE-sorter was run using [`f1_braker-TESorter.slurm`](f1_braker-TESorter.slurm). The list of potential TE containing genes were prepared using:

```bash
grep -v "^#" augustus.hints.codingseq.rexdb-plant.cls.tsv | cut -f 1 | sort | uniq > TE.braker.ids
grep "\.t1$" TE.braker.ids | awk '{print $1"\tTE-containing-gene"}' > TE-primary-ids.txt
# TE table
grep "\.t1$" ids.all > all-primary-ids.txt
grep -Fwv -f <(cut -f 1 TE-primary-ids.txt) all-primary-ids.txt | awk '{print $1"\tnon-TE-genes"}' > nonTE-primary-ids.txt
cat TE-primary-ids.txt nonTE-primary-ids.txt > TE-info.txt
```

### 2. Expression


For BRAKER gene models:

```bash
dataset1=dataset1_r2_Aligned.sortedByCoord.out.bam
dataset2=dataset2_r2_Aligned.sortedByCoord.out.bam
gff=augustus.hints.gtf
gtf=augustus.hints.gff3
featureCounts -T 36 -a $gtf -p --tmpDir $TMPDIR -g "transcript_id" -B -C --primary  -o readcounts-braker.transcript-level $dataset1 $dataset2
cut -f 1 transcript-level-counts.tsv | grep -v "^Geneid" > ids.all
# expression table
grep -v "^#" readcoutns-braker.transcript-level | cut -f 1,6- > count-info.txt
```


### 3. Phylostrata

For BRAKER transcritps, phylostrata was run as using [`runPhylostrata.sh`](runPhylostrata.sh). This script also requires to run Diamond using [`runDiamondBLASTP.sh`](runDiamondBLASTP.sh). Once completed, the results were filtered as follows:

```bash
cat phylostrata_table.csv |\
   sed 's/,/\t/g' |\
   sed 's/"//g' |\
   sed 's/ /_/g' |\
   cut -f 2,5 |\
   grep -v "^qseqid" > assigned-ps.temp
grep -Fwv -f <(cut -f 1 assigned-ps.temp) ids.all |\
   awk '{print $1"\tunclassified"}' > unassigned-ps.temp
cat assigned-ps.temp unassigned-ps.temp > ps-info.txt
# remove intermediary files
rm assigned-ps.temp unassigned-ps.temp
```


### 4. Orthogroups

From Phytozome, proteomes for the following spp were downloaded:

<details>
<summary>Species List</summary>

```
Bdistachyon_556_v3.2.protein_primary.fasta
Bhybridum_463_v1.1.protein_primary.fasta
Bmexicanum_577_v1.1.protein_primary.fasta
Bstacei_316_v1.1.protein_primary.fasta
Bsylvaticum_490_v1.1.protein_primary.fasta
Ecoracana_560_v1.1.protein_primary.fasta
Hvulgare_462_r1.protein_primary.fasta
Msinensis_497_v7.1.protein_primary.fasta
Osativa_323_v7.0.protein_primary.fasta
OsativaKitaake_499_v3.1.protein_primary.fasta
Othomaeum_386_v1.0.protein_primary.fasta
Phallii_308_v2.0.protein_primary.fasta
Phallii_495_v3.1.protein_primary.fasta
PhalliiHAL_496_v2.1.protein_primary.fasta
Pvirgatum_450_v4.1.protein_primary.fasta
Pvirgatum_516_v5.1.protein_primary.fasta
Sbicolor_454_v3.1.1.protein_primary.fasta
Sitalica_312_v2.2.protein_primary.fasta
Sviridis_311_v1.1.protein_primary.fasta
Sviridis_500_v2.1.protein_primary.fasta
Taestivum_296_v2.2.protein_primary.fasta
Tintermedium_503_v2.1.protein_primary.fasta
zea_maysb73_core_3_87_1.protein_primary.fasta
```

</details>


BRAKER primary proteins were extracted to generate `sangu_braker_primary.fasta`. All files were saved in the `clean-fa` folder and [`runOrthofinder.sh`](runOrthofinder.sh) was used to assign orthogroups for predictions.

After completion, results were formatted as follows:

```bash
# orthogroup table
cd OrthoFinder/Results_Oct21/Orthogroups
awk '$NF==$24 {print $1}' Orthogroups.GeneCount.tsv > doubtful.ids
grep -Fw -f doubtful.ids Orthogroups.txt > doubtful-list.txt
sed 's/: /\t/1' doubtful-list.txt |cut -f 2- |tr " " "\n" |awk '{print $0"\tno-OG-support"}' > list1.txt
cut -f 1,24 Orthogroups_UnassignedGenes.tsv |awk 'NF>1' > doubtful-list-from-unassigned.txt
awk '{print $2"\tunassigned-OG"}' doubtful-list-from-unassigned.txt | grep -v "^sangu_braker_primary" > list2.txt
cat list1.txt list2.txt > full-list.txt
grep -Fwv -f <(cut -f 1 full-list.txt) ids.all |awk '{print $1"\tOG-supported"}' > rest-list.txt
cat full-list.txt rest-list.txt >> orthogroup-info.txt
```

### 5. Performing filtering on _ab initio_ gene models

The tables generated in the above steps are combined to create a formatted table
```bash
# merge all files to one
awk 'BEGIN{OFS=FS="\t"}FNR==NR{a[$1]=$2;next}{ print $0, a[$1]}' TE-info.txt count-info.txt > count-te-info.txt
awk 'BEGIN{OFS=FS="\t"}FNR==NR{a[$1]=$2;next}{ print $0, a[$1]}' orthogroup-info.txt count-te-info.txt > count-te-og-info.txt
awk 'BEGIN{OFS=FS="\t"}FNR==NR{a[$1]=$2;next}{ print $0, a[$1]}' ps-info.txt count-te-og-info.txt > count-te-og-ps-info.txt
rm count-te-info.txt count-te-og-info.txt
# filter braker
awk '(($5=="genic" && $6=="OG-supported") && $NF!="Streptochaeta_angustifolia")' count-te-og-ps-info.txt  > count-te-og-ps-to-keep.txt
cut -f 1 count-te-og-ps-to-keep.txt |cut -f 1 -d "." |sort |uniq > to-keep.txt
mikado util grep --genes to-keep.txt augustus.hints.gff3 > braker-og-ps-exp-filtered.gff3
```



## IV Filtering Direct-Evidence


### 1. TE containing genes

To filter TE containing genes Direct-Evidence, TE-sorter was run using [`f2_direct_evidence-TESorter.slurm`](f2_direct_evidence-TESorter.slurm). The list of potential TE containing genes were prepared using:

```bash
grep -v "^#" mikado-coding-cds.fa.rexdb-plant.cls.tsv | cut -f 1 | sort | uniq > TE.mikado.ids
```

### 2. Expression

For the direct-evidence gene models, only genes with some expression evidence was retained.

```bash
dataset1=dataset1_r2_Aligned.sortedByCoord.out.bam
dataset2=dataset2_r2_Aligned.sortedByCoord.out.bam
gff=mikado-coding.gff3
gtf=mikado-coding.gtf
mikado util convert -of gtf -if gff3 $gff $gtf
featureCounts -T 36 -a $gtf -p --tmpDir $TMPDIR -B -C --primary  -o readcoutns-mikado.gene-level $dataset1 $dataset2
cut -f 1,7,8  readcoutns-mikado.gene-level | grep -v "^#" > temp-gene
awk '{print $0"\t"$2+$3}' temp-gene > gene-level-counts.tsv
```

### 2. Performing filtering on direct-evidence gene models

Performing actual filtering:

```bash
awk '$4>=10' gene-level-counts.tsv |cut -f 1 | grep -v ^Geneid > with-expression.ids
grep -Fw -f TE.mikado.ids with-expression.ids > mikado-to-keep.ids
mikado util grep --genes mikado-to-keep.ids mikado-coding.gff3 > mikado-coding-expression-filtered.gff3
```


## V Merge Direct-Evidence with _ab initio_ gene models

### Run Mikado compare

```bash
BR=braker-og-ps-exp-filtered.gff3
DI=mikado-coding-expression-filtered.gff3
mikado compare -r $DI -p $BR -o mikado-braker-compared
cut -f 3 mikado-braker-compared.tmap |grep -v "ccode" |sort |uniq -c |awk '{print $2"\t"$1}' > ccode-counts.txt
cut -f 3 mikado-braker-compared.tmap |grep -v "ccode" |sort |uniq > ccodes.txt
tmap="mikado-braker-compared.tmap"
```

### Create ccodes files (flag ids for removal)

   - ccode to remove from direct evidence: [`remove-evidence.txt`](assets/remove-evidence.txt)
   - ccode to remove from ab initio: [`remove-braker.txt`](assets/remove-braker.txt)

### Generate list of ids to remove

For evidence

```bash
while read line; do
  awk -v x=${line} '$3==x {print $1"\t"$2}' $tmap;
done<remove-evidence.txt > evidence-ids-to-remove.txt
```

For Braker

```bash
while read line; do
  awk -v x=${line} '$3==x {print $4"\t"$5}' $tmap;
done<remove-braker.txt > braker-ids-to-remove.txt
```

### Perform removal

```bash
mikado util grep -v evidence-ids-to-remove.txt $DI  > DI_clean.gff3
mikado util grep -v braker-ids-to-remove.txt $BR > BR_clean.gff3
```

### Merge
```bash
agat_sp_merge_annotations.pl --gff BR_clean.gff3 --gff DI_clean.gff3 --out BIND-merged-final.gff3
```
